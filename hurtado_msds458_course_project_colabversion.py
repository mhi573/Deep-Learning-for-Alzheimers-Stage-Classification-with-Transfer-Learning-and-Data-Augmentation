# -*- coding: utf-8 -*-
"""Hurtado_MSDS458_Course Project_ColabVersion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DD500ZnMHxo-F1PRMHpO_WldYno2Cgxp

# <center><font color="navy">Classification of Alzheimer's Disease Stage Diagnosis:<br />A Benchmark Analysis of Convolutional Neural Network (CNN) Application Utilizing MRI Images</font></center>

# Read the data in, and conducted an exploratory data analysis
### First, we will set up this notebook so that it will display multiple outputs for each cell if needed, as well as load the necessary libraries.
"""

from IPython.core.interactiveshell import InteractiveShell
from IPython.display import display, HTML
import pandas as pd

InteractiveShell.ast_node_interactivity = "all"

#####################################
#
#   Set Screen Attributes
#
#####################################
# set cell width
display(HTML("<style>.container { width:100% !important; }</style>"))

# set cell output window height
display(HTML("<style>div.output_scroll { height: 160em;} </style>"))

pd.set_option('display.max_rows', 500)
pd.set_option('display.max_columns', 500)
pd.set_option('display.width', 1000)

from tensorflow.keras.preprocessing.image import ImageDataGenerator

import shutil
import os
from google.colab import files
import seaborn as sns
import matplotlib.pyplot as plt

#pip install opencv-python-headless

#pip install opencv-python

import numpy as np
import cv2

#pip install tensorflow

pip install keras_tuner

import tensorflow as tf
import keras
from tensorflow.keras.utils import to_categorical
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
import keras_tuner as kt
from tensorflow.keras.models import Sequential, Model, load_model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input, GlobalAveragePooling2D
from tensorflow.keras import backend as K
from tensorflow.keras.metrics import AUC, Precision, Recall
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from sklearn.metrics import confusion_matrix, classification_report
from tensorflow.keras.optimizers import SGD, Adam
from sklearn.model_selection import LeaveOneOut
from sklearn.model_selection import KFold
from tensorflow.keras import layers
from sklearn.model_selection import StratifiedKFold
from sklearn.utils import shuffle
from sklearn.utils.class_weight import compute_class_weight
from tensorflow.keras.applications import InceptionV3, VGG16
from tensorflow.keras.applications.inception_v3 import preprocess_input

"""## <b>Load the data:

### README INFO:

---
dataset_info:
  features:
  - name: image
    dtype: image
  - name: label
    dtype:
      class_label:
        names:
          '0': Mild_Demented
          '1': Moderate_Demented
          '2': Non_Demented
          '3': Very_Mild_Demented
  splits:
  - name: train
    num_bytes: 22560791.2
    num_examples: 5120
  - name: test
    num_bytes: 5637447.08
    num_examples: 1280
  download_size: 28289848
  dataset_size: 28198238.28
license: apache-2.0
task_categories:
- image-classification
language:
- en
tags:
- medical
pretty_name: Alzheimer_MRI Disease Classification Dataset
size_categories:
- 1K<n<10K
---
## Alzheimer_MRI Disease Classification Dataset

The Falah/Alzheimer_MRI Disease Classification dataset is a valuable resource for researchers and health medicine applications. This dataset focuses on the classification of Alzheimer's disease based on MRI scans. The dataset consists of brain MRI images labeled into four categories:

- '0': Mild_Demented
- '1': Moderate_Demented
- '2': Non_Demented
- '3': Very_Mild_Demented

### Dataset Information

- Train split:
  - Name: train
  - Number of bytes: 22,560,791.2
  - Number of examples: 5,120

- Test split:
  - Name: test
  - Number of bytes: 5,637,447.08
  - Number of examples: 1,280

- Download size: 28,289,848 bytes
- Dataset size: 28,198,238.28 bytes

### Citation

If you use this dataset in your research or health medicine applications, we kindly request that you cite the following publication:
```
@dataset{alzheimer_mri_dataset,
  author = {Falah.G.Salieh},
  title = {Alzheimer MRI Dataset},
  year = {2023},
  publisher = {Hugging Face},
  version = {1.0},
  url = {https://huggingface.co/datasets/Falah/Alzheimer_MRI}
}
```


### Usage Example

Here's an example of how to load the dataset using the Hugging Face library:

```python
from datasets import load_dataset

# Load the Falah/Alzheimer_MRI dataset
dataset = load_dataset('Falah/Alzheimer_MRI', split='train')

# Print the number of examples and the first few samples
print("Number of examples:", len(dataset))
print("Sample data:")
for example in dataset[:5]:
    print(example)
```
"""

def disease_label_from_category(category):
    labels = {0: "Mild_Demented", 1: "Moderate_Demented", 2: "Non_Demented", 3: "Very_Mild_Demented"}
    return labels.get(category, "Unknown")

os.getcwd()

#set working Directory
#os.chdir('/Users/mhurt/Documents/MSDS458/Course Project')

#pip install shutil

# Move kaggle.json to the right location
#shutil.move("kaggle.json", os.path.expanduser("~/.kaggle/"))

# Set proper permissions
#os.chmod(os.path.expanduser("~/.kaggle/kaggle.json"), 600)

!kaggle datasets download -d borhanitrash/alzheimer-mri-disease-classification-dataset --unzip

# Define source and destination paths
testdata_path = "C:/Users/mhurt/Documents/MSDS458/Course Project/Alzheimer MRI Disease Classification Dataset/Data/test-00000-of-00001-44110b9df98c5585.parquet"
traindata_path = "C:/Users/mhurt/Documents/MSDS458/Course Project/Alzheimer MRI Disease Classification Dataset/Data/train-00000-of-00001-c08a401c53fe5312.parquet"
destination_path = os.getcwd()

# Move the file
shutil.move(testdata_path, destination_path)
shutil.move(traindata_path, destination_path)

uploaded = files.upload()

test_data = "test-00000-of-00001-44110b9df98c5585.parquet"
train_data = "train-00000-of-00001-c08a401c53fe5312.parquet"

test_data = pd.read_parquet(test_data)
train_data = pd.read_parquet(train_data)


test_data.head()  # Display the first few rows

train_data.head()

"""# <b><center><br /><br />Investigation of Data, Missingness, and Outliers in Testing and Training Data

## <b><br /><br />Test data:<br /><br />
"""

# find null counts, percentage of null values, and column type
null_count = test_data.isnull().sum()
null_percentage = test_data.isnull().sum() * 100 / len(test_data)
column_type = test_data.dtypes

# show null counts, percentage of null values, and column type for columns with more than one Null value
null_summary = pd.concat([null_count, null_percentage, column_type], axis=1, keys=['Missing Count', 'Percentage Missing','Column Type'])
null_summary_only_missing = null_summary[null_count != 0].sort_values('Percentage Missing',ascending=False)
null_summary_only_missing

def dict_to_image(image_dict):
    if isinstance(image_dict, dict) and 'bytes' in image_dict:
        byte_string = image_dict['bytes']
        nparr = np.frombuffer(byte_string, np.uint8)
        img = cv2.imdecode(nparr, cv2.IMREAD_GRAYSCALE)
        return img
    else:
        raise TypeError(f"Expected dictionary with 'bytes' key, got {type(image_dict)}")

test_data['img_arr'] = test_data['image'].apply(dict_to_image)
test_data.drop("image", axis=1, inplace=True)
test_data.head()

train_data['img_arr'] = train_data['image'].apply(dict_to_image)
train_data.drop("image", axis=1, inplace=True)
train_data

# Check the type of the 'label' column
print(f"Original type of 'label' column: {test_data['label'].dtype}")

# Convert the 'label' column to numerical values
test_data['label'] = pd.to_numeric(test_data['label'], errors='coerce')  # Convert to numeric, 'coerce' will turn errors into NaN

# Check the type again after conversion
print(f"New type of 'label' column: {test_data['label'].dtype}")

# Optionally, check the updated DataFrame
print(test_data)

# Check we can actually render the image and that it looks reasonable
fig, ax = plt.subplots(2, 3, figsize=(15, 5))
axs = ax.flatten()

for axes in axs:
    rand = np.random.randint(0, len(test_data))
    axes.imshow(test_data.iloc[rand]['img_arr'], cmap="gray")
    axes.set_title(disease_label_from_category(test_data.iloc[rand]['label']))
plt.tight_layout()
plt.show()

# Map the numeric labels to disease categories
#test_data['label'] = test_data['label'].map(disease_label_from_category)

# Count the occurrences of each label
test_label_counts = test_data['label'].value_counts().sort_index()

# Sort the test_label_counts by value in increasing order
test_label_counts = test_label_counts.sort_values()

# Set up the aesthetics using Seaborn
sns.set(style="whitegrid")  # White background with gridlines

# Create a dictionary for custom label names
custom_labels = {
    'Mild_Demented': "Mild Dementia",
    'Moderate_Demented': "Moderate Dementia",
    'Non_Demented': "No Dementia",
    'Very_Mild_Demented': "Very Mild Dementia"
}

# Create the bar plot
plt.figure(figsize=(8, 6))  # Set the figure size
ax = sns.barplot(x=test_label_counts.index, y=test_label_counts.values, palette='viridis', legend=False, hue=test_label_counts.index)

# Set labels and title
ax.set_xlabel("Alzheimer's Disease Stage Labels", fontsize=14, fontweight='bold', labelpad=15)
ax.set_ylabel("Frequency", fontsize=14, fontweight='bold', labelpad=15)
ax.set_title("Table 2. Frequency of Test Data Labels", fontsize=16, fontweight='bold')

# Customize the tick marks and labels
# Replace the x-tick labels with custom labels
ax.set_xticklabels([custom_labels.get(label, label) for label in test_label_counts.index], ha='right', fontsize=12)

ax.set_yticklabels(ax.get_yticklabels(), fontsize=12)

# Add value annotations (frequency) on top of each bar
for p in ax.patches:
    height = p.get_height()
    ax.text(p.get_x() + p.get_width() / 2., height + 0.1,  # Positioning the text on top of the bar
            f'{height:.0f}',  # Value format
            ha='center', va='bottom', fontsize=12, color='black')

# Display the plot
plt.tight_layout()
#plt.savefig('test_data_label_freqs.png', format='png', dpi=300)  # Save with 300 DPI for better resolution
plt.show()

"""## <b><br /><br />Train data:<br /><br />"""

# find null counts, percentage of null values, and column type
null_count = train_data.isnull().sum()
null_percentage = train_data.isnull().sum() * 100 / len(train_data)
column_type = train_data.dtypes

# show null counts, percentage of null values, and column type for columns with more than one Null value
null_summary = pd.concat([null_count, null_percentage, column_type], axis=1, keys=['Missing Count', 'Percentage Missing','Column Type'])
null_summary_only_missing = null_summary[null_count != 0].sort_values('Percentage Missing',ascending=False)
null_summary_only_missing

# Check the type of the 'label' column
print(f"Original type of 'label' column: {train_data['label'].dtype}")

# Convert the 'label' column to numerical values
test_data['label'] = pd.to_numeric(train_data['label'], errors='coerce')  # Convert to numeric, 'coerce' will turn errors into NaN

# Check the type again after conversion
print(f"New type of 'label' column: {train_data['label'].dtype}")

# Optionally, check the updated DataFrame
print(train_data)

# Check we can actually render the image and that it looks reasonable
fig, ax = plt.subplots(2, 3, figsize=(15, 5))
axs = ax.flatten()

for axes in axs:
    rand = np.random.randint(0, len(train_data))
    axes.imshow(train_data.iloc[rand]['img_arr'], cmap="gray")
    axes.set_title(disease_label_from_category(train_data.iloc[rand]['label']))
plt.tight_layout()
plt.show()

# Map the numeric labels to disease categories
#train_data['label'] = train_data['label'].map(disease_label_from_category)

# Count the occurrences of each label
train_label_counts = train_data['label'].value_counts().sort_index()

# Sort the test_label_counts by value in increasing order
train_label_counts = train_label_counts.sort_values()

# Set up the aesthetics using Seaborn
sns.set(style="whitegrid")  # White background with gridlines

# Create the bar plot
plt.figure(figsize=(8, 6))  # Set the figure size
ax = sns.barplot(x=train_label_counts.index, y=train_label_counts.values, palette='viridis', legend=False, hue=train_label_counts.index)

# Set labels and title
ax.set_xlabel("Alzheimer's Disease Stage Labels", fontsize=14, fontweight='bold', labelpad=15)
ax.set_ylabel("Frequency", fontsize=14, fontweight='bold', labelpad=15)
ax.set_title("Table 1. Frequency of Train Data Labels", fontsize=16, fontweight='bold')

# Customize the tick marks and labels
# Replace the x-tick labels with custom labels
ax.set_xticklabels([custom_labels.get(label, label) for label in train_label_counts.index], ha='right', fontsize=12)
ax.set_yticklabels(ax.get_yticklabels(), fontsize=12)

# Add value annotations (frequency) on top of each bar
for p in ax.patches:
    height = p.get_height()
    ax.text(p.get_x() + p.get_width() / 2., height + 0.1,  # Positioning the text on top of the bar
            f'{height:.0f}',  # Value format
            ha='center', va='bottom', fontsize=12, color='black')

# Display the plot
plt.tight_layout()
#plt.savefig('train_data_label_freqs.png', format='png', dpi=300)  # Save with 300 DPI for better resolution
plt.show()

"""<br /><br/>
# <b><center><font color="navy">Experiment 1a: <br /> Building a Simple CNN for MRI Image Classification: A Foundational Approach
<br /><br />

## Prepare the data for CNN
"""

# Access the first image: TEST DATA
image_array = test_data.iloc[0]['img_arr']

# Check the number of dimensions in the image array
if len(image_array.shape) == 2:
    # Grayscale image (height, width)
    height, width = image_array.shape
elif len(image_array.shape) == 3:
    # RGB image (height, width, channels)
    height, width, channels = image_array.shape
    print(f"Channels: {channels}")  # This will print the number of color channels (typically 3 for RGB)
else:
    raise ValueError("Unexpected image shape")

print(f"Image Size: {height}x{width} pixels")

# Access the first image: TRAIN DATA
image_array = train_data.iloc[0]['img_arr']

# Check the number of dimensions in the image array
if len(image_array.shape) == 2:
    # Grayscale image (height, width)
    height, width = image_array.shape
elif len(image_array.shape) == 3:
    # RGB image (height, width, channels)
    height, width, channels = image_array.shape
    print(f"Channels: {channels}")  # This will print the number of color channels (typically 3 for RGB)
else:
    raise ValueError("Unexpected image shape")

print(f"Image Size: {height}x{width} pixels and {channels} channels.")

X_train = np.stack(train_data['img_arr'].values)  # Convert list of arrays into a single 4D NumPy array
X_test = np.stack(test_data['img_arr'].values)  # Convert list of arrays into a single 4D NumPy array

# Ensure the shape is (num_samples, 128, 128, 1) for grayscale images
if X_train.ndim == 3:
    X_train = np.expand_dims(X_train, axis=-1)
if X_test.ndim == 3:
    X_test = np.expand_dims(X_test, axis=-1)

# Normalize images to range [0,1] if necessary
X_train = X_train.astype('float32') / 255.0
X_test = X_test.astype('float32') / 255.0

label_encoder = LabelEncoder()
y_train_encoded = label_encoder.fit_transform(train_data['label'])  # Convert labels to integers
y_test_encoded = label_encoder.fit_transform(test_data['label'])  # Convert labels to integers

# Check the unique mapping (useful for debugging)
print(dict(zip(label_encoder.classes_, range(len(label_encoder.classes_)))))

# Convert to one-hot encoding
num_classes = len(np.unique(y_train_encoded))
y_train_one_hot = to_categorical(y_train_encoded, num_classes=num_classes)
y_test_one_hot = to_categorical(y_test_encoded, num_classes=num_classes)

# Split training data into training and validation sets (80% train, 30% val)
X_train_final, X_val, y_train_final, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.3, random_state=42, stratify=y_train_encoded)

# Print final shapes
print(f"Training set: {X_train_final.shape}, {y_train_final.shape}")
print(f"Validation set: {X_val.shape}, {y_val.shape}")
print(f"Test set: {X_test.shape}, {y_test_one_hot.shape}")

"""## Set Initial Parameters
### <b>Final Structure:
<ol><li><b>Training Set: X_train_final, y_train_final</li>
<li><b>Validation Set: X_val, y_val</li>
<li><b>Test Set: X_test, y_test_one_hot</li> <br />
"""

# Clear session to avoid memory issues
K.clear_session()

metrics=['accuracy', AUC(), Precision(), Recall()]

# Define the callbacks
early_stopping = EarlyStopping(
    monitor='val_loss',  # Monitor validation loss
    patience=10,  # Stop training if val_loss does not improve for 5 consecutive epochs
    restore_best_weights=True  # Restore the best model weights after stopping
    )

model_checkpoint = ModelCheckpoint(
    'best_model.keras',  # Save the best model
    monitor='val_accuracy',  # Track validation accuracy
    save_best_only=True,  # Only save models that improve on validation accuracy
    mode='max',  # Higher validation accuracy is better
    verbose=1
    )

model = Sequential([
    # Input Layer
    Conv2D(32, (3,3), activation='leaky_relu', padding='same', input_shape=(128, 128, 1)),
    BatchNormalization(),
    MaxPooling2D((2,2)),

    # Second Conv Block
    Conv2D(64, (3,3), activation='leaky_relu', padding='same'),
    BatchNormalization(),
    Conv2D(64, (3,3), activation='leaky_relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D((2,2)),

    # Third Conv Block
    Conv2D(128, (3,3), activation='leaky_relu', padding='same'),
    BatchNormalization(),
    Conv2D(128, (3,3), activation='leaky_relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D((2,2)),

    # Fourth Conv Block
    Conv2D(256, (3,3), activation='leaky_relu', padding='same'),
    BatchNormalization(),
    Conv2D(256, (3,3), activation='leaky_relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D((2,2)),

    # Flatten layer
    Flatten(),

    # Fully Connected Layers
    Dense(512, activation='leaky_relu'),
    Dropout(0.3),
    Dense(256, activation='leaky_relu'),
    Dropout(0.3),

    # Output Layer
    Dense(4, activation='softmax')  # 4 classes
])

#CNN 1 at learning_rate=0.0001: 10 epochs, 64 batch size, dropout layers set  to 0.5 w/ relu. accuracy was 78% train, 52% test
#CNN 8 at learning_rate=0.0001: 10 epochs, 128 batch size, dropout layers set  to 0.5 w/ leaky relu . accuracy was 87% train, 43% test
#CNN 7 at learning_rate=0.0001: 10 epochs, 64 batch size, dropout layers set  to 0.5 w/ leaky relu. accuracy was 92% train, 69% test
#CNN 9 at learning_rate=0.0001: 10 epochs, 128 batch size, dropout layers set  to 0.3 w/ leaky relu . accuracy was 98% train, 58% test
#CNN 5 at learning_rate 0.0001: 10 epochs, 64 batch size, dropout layers set to 0.3, w/ leaky_relu. accuracy 98% train, 68% test
optimizer = Adam(learning_rate=0.0001)

#CNN 4 (need to redo) at learning_rate=0.001: 10 epochs, 64 batch size, dropout layers set  to 0.5 w/ relu. accuracy was % train, % test
#CNN 6 at learning_rate 0.001: 10 epochs, 64 batch size, dropout layers set to 0.3 w/ leaky_relu. accuracy 54% train, 19% test
#optimizer = Adam(learning_rate=0.001)

#CNN 2 (need to redo) at learning_rate=0.01: 10 epochs, 64 batch size, dropout layers set  to 0.5 and relu. accuracy was % train, % test#
#optimizer = Adam(learning_rate=0.01)

#CNN 10 at learning rate 0.01 and momentum is 0.0: 10 epochs, 64 batch size, dropout layers set to 0.3 w/ leaky relu. accuracy was 52% train, 36% test
#CNN 11 at learning rate 0.01, momentum = 0.9: NO
#CNN 12 at learning rate 0.1, momentum = 0.9: NO
#CNN 13 at learning rate 0.005, momentum = 0.95: No
#CNN 14 at learning rate 0.001, momentum = 0.5: No
#CNN 15 at learning rate 0.1, momentum = 0.6:
#CNN 16 at learning rate 0.001, momentum = 0.99:
#CNN 17 at learning rate 0.2, momentum = 0.3:
#optimizer = SGD(learning_rate=0.001, momentum = 0.5)

# Compile model
model.compile(optimizer=optimizer,
              loss='categorical_crossentropy',
              metrics=metrics)

# Model Summary
model.summary()

"""## <center><font color="navy"> First set of ablation and optimization experiments: relu activation function

### CNN 1 <br />First attempt at learning_rate=0.0001: 10 epochs, 64 batch size, dropout layers set  to 0.5... the accuracy was 78%, 52% test
"""

cnn_1 = model.fit(
                X_train_final, y_train_final,  # Training data
                validation_data=(X_val, y_val),  # Validation data
                epochs=10,  # Number of training cycles
                batch_size=64,  # Adjust batch size based on available memory
                verbose=1  # Shows progress during training
)

# Extract training history
epochs = range(1, len(cnn_1.history['accuracy']) + 1)

# Plot Accuracy
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(epochs, cnn_1.history['accuracy'], label='Training Accuracy')
plt.plot(epochs, cnn_1.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training vs Validation Accuracy')

# Plot Loss
plt.subplot(1, 2, 2)
plt.plot(epochs, cnn_1.history['loss'], label='Training Loss')
plt.plot(epochs, cnn_1.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Training vs Validation Loss')

plt.show()

test_acc = model.evaluate(X_test, y_test_one_hot, verbose=1)
print(f"Test Accuracy: {test_acc}")

"""### CNN 3 <br />Third attempt at learning_rate=0.0001: 10 epochs, 128 batch size, dropout layers set  to 0.5... the accuracy was 48% train, 47% test"""

cnn_3 = model.fit(
                X_train_final, y_train_final,  # Training data
                validation_data=(X_val, y_val),  # Validation data
                epochs=10,  # Number of training cycles
                batch_size=128,  # Adjust batch size based on available memory
                verbose=1  # Shows progress during training
)

# Extract training history
epochs = range(1, len(cnn_3.history['accuracy']) + 1)

# Plot Accuracy
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(epochs, cnn_3.history['accuracy'], label='Training Accuracy')
plt.plot(epochs, cnn_3.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training vs Validation Accuracy')

# Plot Loss
plt.subplot(1, 2, 2)
plt.plot(epochs, cnn_3.history['loss'], label='Training Loss')
plt.plot(epochs, cnn_3.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Training vs Validation Loss')

plt.show()

test_acc = model.evaluate(X_test, y_test_one_hot, verbose=1)
print(f"Test Accuracy: {test_acc}")

"""### CNN 4 <br />Fourth attempt at learning_rate=0.001: 10 epochs, 64 batch size, dropout layers set  to 0.5... the accuracy was"""

cnn_4 = model.fit(
                X_train_final, y_train_final,  # Training data
                validation_data=(X_val, y_val),  # Validation data
                epochs=10,  # Number of training cycles
                batch_size=64,  # Adjust batch size based on available memory
                verbose=1  # Shows progress during training
)

# Extract training history
epochs = range(1, len(cnn_4.history['accuracy']) + 1)

# Plot Accuracy
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(epochs, cnn_4.history['accuracy'], label='Training Accuracy')
plt.plot(epochs, cnn_4.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training vs Validation Accuracy')

# Plot Loss
plt.subplot(1, 2, 2)
plt.plot(epochs, cnn_4.history['loss'], label='Training Loss')
plt.plot(epochs, cnn_4.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Training vs Validation Loss')

plt.show()

test_acc = model.evaluate(X_test, y_test_one_hot, verbose=1)
print(f"Test Accuracy: {test_acc}")

"""### CNN 2 <br />Second attempt at learning_rate=0.01: 10 epochs, 64 batch size, dropout layers set  to 0.5... the accuracy was 50% train, 47% test"""

cnn_2 = model.fit(
                X_train_final, y_train_final,  # Training data
                validation_data=(X_val, y_val),  # Validation data
                epochs=10,  # Number of training cycles
                batch_size=64,  # Adjust batch size based on available memory
                verbose=1  # Shows progress during training
)

# Extract training history
epochs = range(1, len(cnn_2.history['accuracy']) + 1)

# Plot Accuracy
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(epochs, cnn_2.history['accuracy'], label='Training Accuracy')
plt.plot(epochs, cnn_2.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training vs Validation Accuracy')

# Plot Loss
plt.subplot(1, 2, 2)
plt.plot(epochs, cnn_2.history['loss'], label='Training Loss')
plt.plot(epochs, cnn_2.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Training vs Validation Loss')

plt.show()

test_acc = model.evaluate(X_test, y_test_one_hot, verbose=1)
print(f"Test Accuracy: {test_acc}")



"""## <center><font color="navy"> Major changes to this next set of experiements: 0.3 dropout layers, and leaky relu activation function

### CNN 5a <br />Fifth attempt at learning_rate=0.0001: 10 epochs, 64 batch size, dropout layers set  to 0.3, and leaky relu... the accuracy was 98% train, 68% test
"""

cnn_5 = model.fit(
                X_train_final, y_train_final,  # Training data
                validation_data=(X_val, y_val),  # Validation data
                epochs=15,  # Number of training cycles
                batch_size=64,  # Adjust batch size based on available memory
                verbose=1,  # Shows progress during training,
                callbacks=[early_stopping, model_checkpoint]

)

# Extract training history
epochs = range(1, len(cnn_5.history['accuracy']) + 1)

# Plot Accuracy
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(epochs, cnn_5.history['accuracy'], label='Training Accuracy')
plt.plot(epochs, cnn_5.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training vs Validation Accuracy')

# Plot Loss
plt.subplot(1, 2, 2)
plt.plot(epochs, cnn_5.history['loss'], label='Training Loss')
plt.plot(epochs, cnn_5.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Training vs Validation Loss')

plt.show()

# Load the best saved model
best_model = load_model('best_model.keras')

# Evaluate on test data
test_acc = best_model.evaluate(X_test, y_test_one_hot, verbose=1)
print(f"Test Accuracy: {test_acc}")

"""### CNN 5b with 5 conv blocks, 5th layer at 512: NO"""

# Extract training history
epochs = range(1, len(cnn_5.history['accuracy']) + 1)

# Plot Accuracy
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(epochs, cnn_5.history['accuracy'], label='Training Accuracy')
plt.plot(epochs, cnn_5.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training vs Validation Accuracy')

# Plot Loss
plt.subplot(1, 2, 2)
plt.plot(epochs, cnn_5.history['loss'], label='Training Loss')
plt.plot(epochs, cnn_5.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Training vs Validation Loss')

plt.show()

# Load the best saved model
best_model = load_model('best_model.keras')

# Evaluate on test data
test_acc = best_model.evaluate(X_test, y_test_one_hot, verbose=1)
print(f"Test Accuracy: {test_acc}")



"""## <center><font color="navy"> Testing dense layers."""

cnn_52 = model.fit(
                X_train_final, y_train_final,  # Training data
                validation_data=(X_val, y_val),  # Validation data
                epochs=10,  # Number of training cycles
                batch_size=64,  # Adjust batch size based on available memory
                verbose=1,  # Shows progress during training,
                callbacks=[early_stopping, model_checkpoint]

)

# Extract training history
epochs = range(1, len(cnn_52.history['accuracy']) + 1)

# Plot Accuracy
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(epochs, cnn_52.history['accuracy'], label='Training Accuracy')
plt.plot(epochs, cnn_52.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training vs Validation Accuracy')

# Plot Loss
plt.subplot(1, 2, 2)
plt.plot(epochs, cnn_52.history['loss'], label='Training Loss')
plt.plot(epochs, cnn_52.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Training vs Validation Loss')

plt.show()

test_acc = model.evaluate(X_test, y_test_one_hot, verbose=1)
print(f"Test Accuracy: {test_acc}")

cnn_53 = model.fit(
                X_train_final, y_train_final,  # Training data
                validation_data=(X_val, y_val),  # Validation data
                epochs=15,  # Number of training cycles
                batch_size=64,  # Adjust batch size based on available memory
                verbose=1,  # Shows progress during training,
                callbacks=[early_stopping, model_checkpoint]

)

# Extract training history
epochs = range(1, len(cnn_53.history['accuracy']) + 1)

# Plot Accuracy
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(epochs, cnn_53.history['accuracy'], label='Training Accuracy')
plt.plot(epochs, cnn_53.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training vs Validation Accuracy')

# Plot Loss
plt.subplot(1, 2, 2)
plt.plot(epochs, cnn_53.history['loss'], label='Training Loss')
plt.plot(epochs, cnn_53.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Training vs Validation Loss')

plt.show()

test_acc = model.evaluate(X_test, y_test_one_hot, verbose=1)
print(f"Test Accuracy: {test_acc}")

"""### CNN 6 <br />Next attempt at learning_rate=0.001: 10 epochs, 64 batch size, dropout layers set  to 0.3, and leaky relu... the accuracy was 54% train, 19% test"""

cnn_6 = model.fit(
                X_train_final, y_train_final,  # Training data
                validation_data=(X_val, y_val),  # Validation data
                epochs=10,  # Number of training cycles
                batch_size=64,  # Adjust batch size based on available memory
                verbose=1  # Shows progress during training
)

# Extract training history
epochs = range(1, len(cnn_6.history['accuracy']) + 1)

# Plot Accuracy
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(epochs, cnn_6.history['accuracy'], label='Training Accuracy')
plt.plot(epochs, cnn_6.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training vs Validation Accuracy')

# Plot Loss
plt.subplot(1, 2, 2)
plt.plot(epochs, cnn_6.history['loss'], label='Training Loss')
plt.plot(epochs, cnn_6.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Training vs Validation Loss')

plt.show()

test_acc = model.evaluate(X_test, y_test_one_hot, verbose=1)
print(f"Test Accuracy: {test_acc}")

"""### CNN 7 <br />Attempt at learning_rate=0.0001: 10 epochs, 64 batch size, <u> dropout layers set  to 0.5 </u>... the accuracy was 92% train, 69% test"""

cnn_7 = model.fit(
                X_train_final, y_train_final,  # Training data
                validation_data=(X_val, y_val),  # Validation data
                epochs=10,  # Number of training cycles
                batch_size=64,  # Adjust batch size based on available memory
                verbose=1  # Shows progress during training
)

# Extract training history
epochs = range(1, len(cnn_7.history['accuracy']) + 1)

# Plot Accuracy
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(epochs, cnn_7.history['accuracy'], label='Training Accuracy')
plt.plot(epochs, cnn_7.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training vs Validation Accuracy')

# Plot Loss
plt.subplot(1, 2, 2)
plt.plot(epochs, cnn_7.history['loss'], label='Training Loss')
plt.plot(epochs, cnn_7.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Training vs Validation Loss')

plt.show()

test_acc = model.evaluate(X_test, y_test_one_hot, verbose=1)
print(f"Test Accuracy: {test_acc}")

"""### CNN 8 <br />Attempt at learning_rate=0.0001: 10 epochs, 128 batch size, <u> dropout layers set  to 0.5 </u>... the accuracy was 87% train, 43% test"""

cnn_8 = model.fit(
                X_train_final, y_train_final,  # Training data
                validation_data=(X_val, y_val),  # Validation data
                epochs=10,  # Number of training cycles
                batch_size=128,  # Adjust batch size based on available memory
                verbose=1  # Shows progress during training
)

# Extract training history
epochs = range(1, len(cnn_8.history['accuracy']) + 1)

# Plot Accuracy
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(epochs, cnn_8.history['accuracy'], label='Training Accuracy')
plt.plot(epochs, cnn_8.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training vs Validation Accuracy')

# Plot Loss
plt.subplot(1, 2, 2)
plt.plot(epochs, cnn_8.history['loss'], label='Training Loss')
plt.plot(epochs, cnn_8.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Training vs Validation Loss')

plt.show()

test_acc = model.evaluate(X_test, y_test_one_hot, verbose=1)
print(f"Test Accuracy: {test_acc}")

"""### CNN 9 <br />Attempt at learning_rate=0.0001: 10 epochs, 128 batch size, <u> dropout layers set  to 0.3 </u>... the accuracy was 98% train, 58% test"""

cnn_9 = model.fit(
                X_train_final, y_train_final,  # Training data
                validation_data=(X_val, y_val),  # Validation data
                epochs=10,  # Number of training cycles
                batch_size=128,  # Adjust batch size based on available memory
                verbose=1  # Shows progress during training
)

# Extract training history
epochs = range(1, len(cnn_9.history['accuracy']) + 1)

# Plot Accuracy
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(epochs, cnn_9.history['accuracy'], label='Training Accuracy')
plt.plot(epochs, cnn_9.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training vs Validation Accuracy')

# Plot Loss
plt.subplot(1, 2, 2)
plt.plot(epochs, cnn_9.history['loss'], label='Training Loss')
plt.plot(epochs, cnn_9.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Training vs Validation Loss')

plt.show()

test_acc = model.evaluate(X_test, y_test_one_hot, verbose=1)
print(f"Test Accuracy: {test_acc}")

"""## <center><font color="navy"> Major changes to this third set of experiments: 0.3 dropout layers, leaky relu activation function, SGD optimizer

### CNN 10 <br />SGD optimizer at learning rate = 0.01 and momemtum = 0.0, 10 epochs, 64 batch size, dropout layers at 0.3 w/ leaky relu
"""

cnn_10 = model.fit(
                X_train_final, y_train_final,  # Training data
                validation_data=(X_val, y_val),  # Validation data
                epochs=10,  # Number of training cycles
                batch_size=64,  # Adjust batch size based on available memory
                verbose=1,  # Shows progress during training
                callbacks=[early_stopping, model_checkpoint]  # Add callbacks
)

# Extract training history
epochs = range(1, len(cnn_10.history['accuracy']) + 1)

# Plot Accuracy
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(epochs, cnn_10.history['accuracy'], label='Training Accuracy')
plt.plot(epochs, cnn_10.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training vs Validation Accuracy')

# Plot Loss
plt.subplot(1, 2, 2)
plt.plot(epochs, cnn_10.history['loss'], label='Training Loss')
plt.plot(epochs, cnn_10.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Training vs Validation Loss')

plt.show()

from tensorflow.keras.models import load_model

# Load the best saved model
best_model = load_model('best_model.h5')

# Evaluate on test data
test_acc = best_model.evaluate(X_test, y_test_one_hot, verbose=1)
print(f"Test Accuracy: {test_acc}")

"""### CNN 11 <br />SGD optimizer at learning rate = 0.01, momentum = 0.9, 10 epochs, 64 batch size, dropout layers at 0.3 w/ leaky relu

### CNN 12 <br />SGD optimizer at learning rate = 0.1, momentum = 0.9, 10 epochs, 64 batch size, dropout layers at 0.3 w/ leaky relu

### CNN 13 <br /> at learning rate 0.005, momentum = 0.95: 10 epochs, 64 batch size, dropout layers set to 0.3 w/ leaky relu. accuracy was % train, % test

### CNN 14 <br /> at learning rate 0.001, momentum = 0.5: 10 epochs, 64 batch size, dropout layers set to 0.3 w/ leaky relu. accuracy was % train, % test

### CNN 15 <br /> at learning rate 0.1, momentum = 0.6: 10 epochs, 64 batch size, dropout layers set to 0.3 w/ leaky relu. accuracy was % train, % test

### CNN 16 <br /> at learning rate 0.001, momentum = 0.99: 10 epochs, 64 batch size, dropout layers set to 0.3 w/ leaky relu. accuracy was % train, % test

### CNN 17 <br />at learning rate 0.2, momentum = 0.3: 10 epochs, 64 batch size, dropout layers set to 0.3 w/ leaky relu. accuracy was % train, % test

## <center><font color="navy">This next section explored simpler architectures (i.e., less blocks) compared to the previous four conv block model:

### Two conv blocks. As a result of previous experiments, the activation function selected was leaky relu, Adam optimizer set at a learning rate of 0.0001, and with a loss function of categorical cross-entropy
"""

def build_model(hp):
    model = Sequential()

    # Explicitly define the input shape
    model.add(Input(shape=(128, 128, 1)))

    # First Conv Block
    model.add(Conv2D(hp.Choice('filters_1', [32, 64]), (3,3), activation='leaky_relu', padding='same'))
    model.add(BatchNormalization())
    model.add(MaxPooling2D((2,2)))

    # Second Conv Block
    model.add(Conv2D(hp.Choice('filters_2', [64, 128, 256]), (3,3), activation='leaky_relu', padding='same'))
    model.add(BatchNormalization())
    model.add(Conv2D(hp.Choice('filters_2', [64, 128, 256]), (3,3), activation='leaky_relu', padding='same'))
    model.add(BatchNormalization())
    model.add(MaxPooling2D((2,2)))

    # Flatten layer
    model.add(Flatten())

    # Fully Connected Layers
    model.add(Dense(hp.Int('dense_units_1', 256, 512, step=128), activation='leaky_relu'))
    model.add(Dropout(hp.Choice('dropout_1', [0.3])))
    model.add(Dense(hp.Int('dense_units_2', 128, 256, step=64), activation='leaky_relu'))
    model.add(Dropout(hp.Choice('dropout_2', [0.3])))

    # Output Layer
    model.add(Dense(4, activation='softmax'))  # 4 classes

    # Compile Model
    model.compile(
        optimizer=Adam(learning_rate=hp.Choice('learning_rate', [1e-4])),
        loss='categorical_crossentropy',
        metrics=metrics
    )

    return model

# Keras Tuner - Random Search
tuner = kt.RandomSearch(
    build_model,
    objective='val_accuracy',
    max_trials=4,  # Number of different models to test
    executions_per_trial=1,  # Number of times each model is trained
    directory='tuner_results',
    project_name='cnn_tuning'
)

# Run the search
tuner.search(X_train_final, y_train_final, epochs=8, validation_data=(X_val, y_val), verbose=1)

best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]
print(best_hps.values)

model = Sequential([

                    # Input Layer (explicitly define input size)
    Input(shape=(128, 128, 1)),  # This is the correct way to define the input shape

    # Input Layer
    Conv2D(32, (3,3), activation='leaky_relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D((2,2)),

    # Second Conv Block
    Conv2D(128, (3,3), activation='leaky_relu', padding='same'),
    BatchNormalization(),
    Conv2D(128, (3,3), activation='leaky_relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D((2,2)),

    # Flatten layer
    Flatten(),

    # Fully Connected Layers
    Dense(512, activation='leaky_relu'),
    Dropout(0.3),
    Dense(192, activation='leaky_relu'),
    Dropout(0.3),

    # Output Layer
    Dense(4, activation='softmax')  # 4 classes
])

best_model = tuner.hypermodel.build(best_hps)
best_model.fit(X_train_final, y_train_final, epochs=8,
               validation_data=(X_val, y_val),
               batch_size= 32,  # Adjust batch size based on available memory
               verbose=1,  # Shows progress during training,
               callbacks=[early_stopping, model_checkpoint]  )

test_acc = best_model.evaluate(X_test, y_test_one_hot, verbose=1)
print(f"Test Accuracy: {test_acc}")

K.clear_session()

# Build the model
model = Sequential([

    # Input Layer (explicitly define input size)
    Input(shape=(128, 128, 1)),  # This is the correct way to define the input shape

    # First Conv Block
    Conv2D(32, (3,3), activation='leaky_relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D((2,2)),

    # Second Conv Block
    Conv2D(128, (3,3), activation='leaky_relu', padding='same'),
    BatchNormalization(),
    Conv2D(128, (3,3), activation='leaky_relu', padding='same'),
    BatchNormalization(),
    MaxPooling2D((2,2)),

    # Flatten layer
    Flatten(),

    # Fully Connected Layers
    Dense(512, activation='leaky_relu'),
    Dropout(0.3),
    Dense(192, activation='leaky_relu'),
    Dropout(0.3),

    # Output Layer
    Dense(4, activation='softmax')  # 4 classes
])

# Compile the model
model.compile(
    optimizer=Adam(learning_rate=0.0001),  # Set your preferred learning rate
    loss='categorical_crossentropy',  # Appropriate loss function for multi-class classification
    metrics=['accuracy']  # Track accuracy as a metric during training
)

# You can now train the model with model.fit()
model.summary()

model.fit(X_train_final, y_train_final, epochs=8,
               validation_data=(X_val, y_val),
               batch_size= 32,  # Adjust batch size based on available memory
               verbose=1,  # Shows progress during training,
               callbacks=[early_stopping, model_checkpoint]  )

test_acc = model.evaluate(X_test, y_test_one_hot, verbose=1)
print(f"Test Accuracy: {test_acc}")

"""### LOOCV"""

# Set up CV
num_classes=num_classes

# Initialize LOOCV
loo = LeaveOneOut()
accuracies = []

# 1. Combine the datasets
combined_data = pd.concat([train_data, test_data], axis=0, ignore_index=True)

# 2. Separate features (X) and labels (y)
X = combined_data['img_arr']  # Features (image arrays)
y = combined_data['label']  # Labels


print(X)
print(y)

X = np.stack(X.values)  # Convert list of arrays into a single 4D NumPy array

# Ensure the shape is (num_samples, 128, 128, 1) for grayscale images
if X.ndim == 3:
    X = np.expand_dims(X, axis=-1)

# Normalize images to range [0,1] if necessary
X = X.astype('float32') / 255.0

label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)  # Convert labels to integers

# Check the unique mapping (useful for debugging)
print(dict(zip(label_encoder.classes_, range(len(label_encoder.classes_)))))

# Convert to one-hot encoding
num_classes = len(np.unique(y))
y_cat = to_categorical(y, num_classes=num_classes)

print(X)
print(y)
print(y_cat)

for train_idx, test_idx in loo.split(X):
    print(f"\nLOOCV Iteration - Test Sample: {test_idx[0]}")

    # Split Data: One sample is test, rest are training
    X_train_cv, X_test_cv = X[train_idx], X[test_idx]
    y_train_cv, y_test_cv = y_cat[train_idx], y_cat[test_idx]

    # Define CNN model
    input_shape=(128,128,1)
    model = keras.Sequential([
        keras.layers.Conv2D(32, (3, 3), activation='leaky_relu', padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.MaxPooling2D((2, 2)),
        keras.layers.Conv2D(128, (3, 3), activation='leaky_relu', padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.Conv2D(128, (3, 3), activation='leaky_relu', padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.MaxPooling2D((2, 2)),
        keras.layers.Flatten(),
        keras.layers.Dense(512, activation='leaky_relu'),
        keras.layers.Dropout(0.3),
        keras.layers.Dense(192, activation='leaky_relu'),
        keras.layers.Dropout(0.3),
        keras.layers.Dense(num_classes, activation='softmax')
    ])

    # Compile model
    model.compile(optimizer=Adam(learning_rate=0.0001),
                  loss='categorical_crossentropy',
                  metrics=metrics)

    # Train model
    model.fit(X_train_cv, y_train_cv, epochs=1, batch_size=32, verbose=1)

    # Evaluate on the Left-Out Test Sample
    acc = model.evaluate(X_test_cv, y_test_cv, verbose=0)
    accuracies.append(acc)
    print(f"Test Accuracy: {acc}")

# Compute Final LOOCV Accuracy
final_accuracy = np.mean(accuracies)
print(f"\nFinal LOOCV Accuracy: {final_accuracy}")

"""### Stratified 5 Kfold CV:"""

# Clear session to avoid memory issues
K.clear_session()

# Shuffle data to ensure randomness
X, y_cat = shuffle(X, y_cat, random_state=42)

# Stratified K-Fold setup
n_splits = 5
skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)

# Function to create CNN model
def create_cnn():
    input_shape=(128,128,1)
    model = keras.Sequential([
        keras.layers.Input(shape=input_shape),  # Explicit input layer
        keras.layers.Conv2D(32, (3, 3), activation='leaky_relu', padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.MaxPooling2D((2, 2)),
        keras.layers.Conv2D(128, (3, 3), activation='leaky_relu', padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.Conv2D(128, (3, 3), activation='leaky_relu', padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.MaxPooling2D((2, 2)),
        keras.layers.Flatten(),
        keras.layers.Dense(512, activation='leaky_relu'),
        keras.layers.Dropout(0.3),
        keras.layers.Dense(192, activation='leaky_relu'),
        keras.layers.Dropout(0.3),
        keras.layers.Dense(num_classes, activation='softmax')
    ])

    model.compile(optimizer=Adam(learning_rate=0.0001),
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    return model

# Store accuracies
accuracies = []
losses = []

# K-Fold Cross-Validation loop
for fold, (train_index, test_index) in enumerate(skf.split(X, y)):
    print(f"Fold {fold+1}/{n_splits}")

    # Split dataset
    X_train_cv, X_test_cv = X[train_index], X[test_index]
    y_train_cv, y_test_cv = y_cat[train_index], y_cat[test_index]

    # Compute Class Weights (use original y labels, not one-hot encoded)
    class_weights = compute_class_weight(class_weight="balanced", classes=np.unique(y), y=y[train_index])
    class_weight_dict = dict(enumerate(class_weights))

    # Create a new CNN model instance for each fold
    model = create_cnn()

    # Train the model
    model.fit(X_train_cv, y_train_cv, epochs=8, batch_size=32,
              verbose=1, class_weight=class_weight_dict)  # Include class weights

    # Evaluate the model
    loss, accuracy = model.evaluate(X_test_cv, y_test_cv, verbose=0)
    accuracies.append(accuracy)
    losses.append(loss)
    print(f"Fold {fold+1} Loss: {loss}, Accuracy: {accuracy}\n")

# Print final cross-validation results
final_loss = np.mean(losses)
final_accuracy = np.mean(accuracies)

print(f"Final Average Loss across {n_splits} folds: {final_loss}")
print(f"Final Average Accuracy across {n_splits} folds: {final_accuracy}")

"""###  5 Kfold CV:"""

# Clear session to avoid memory issues
K.clear_session()# Initialize 10-fold cross-validation
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# Store accuracy results
accuracy_per_fold = []
loss_per_fold = []

# Callbacks
checkpoint = ModelCheckpoint(
        '10kfold_mri_model.keras',
        monitor='val_accuracy',
        save_best_only=True,
        mode='max',
        verbose=1
    )

early_stopping = EarlyStopping(
    monitor='val_loss',  # Monitor validation loss
    patience=4,  # Stop training if val_loss does not improve for 5 consecutive epochs
    restore_best_weights=True  # Restore the best model weights after stopping
    )

def create_cnn():
    input_shape=(128,128,1)
    model = keras.Sequential([
        keras.layers.Input(shape=input_shape),  # Explicit input layer
        keras.layers.Conv2D(32, (3, 3), activation='leaky_relu', padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.MaxPooling2D((2, 2)),
        keras.layers.Conv2D(128, (3, 3), activation='leaky_relu', padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.Conv2D(128, (3, 3), activation='leaky_relu', padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.MaxPooling2D((2, 2)),
        keras.layers.Flatten(),
        keras.layers.Dense(512, activation='leaky_relu'),
        keras.layers.Dropout(0.3),
        keras.layers.Dense(192, activation='leaky_relu'),
        keras.layers.Dropout(0.3),
        keras.layers.Dense(num_classes, activation='softmax')
    ])

    model.compile(optimizer=Adam(learning_rate=0.0001),
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    return model

# Perform cross-validation
for fold_no, (train_idx, val_idx) in enumerate(kf.split(X), start=1):
    print(f"\nTraining on Fold {fold_no}/5...")

    # Split data into training and validation sets
    x_train_fold, x_val_fold = X[train_idx], X[val_idx]
    y_train_fold, y_val_fold = y_cat[train_idx], y_cat[val_idx]

    # Create a new model instance for each fold
    model = create_cnn()

    # Train the model
    model.fit(
        x_train_fold, y_train_fold,
        epochs=8, batch_size=64,
        validation_data=(x_val_fold, y_val_fold),
        verbose=1,
        callbacks=[checkpoint, early_stopping]
    )

        # Evaluate the model
    loss, accuracy = model.evaluate(x_val_fold, y_val_fold, verbose=0)
    print(f"Fold {fold_no} - Loss: {loss}, Accuracy: {accuracy}")

    # Store results
    loss_per_fold.append(loss)
    accuracy_per_fold.append(accuracy)

# Print final cross-validation results
print("\nCross-Validation Results:")
print(f"Final Average Accuracy: {np.mean(accuracy_per_fold)}")
print(f"Final Average Loss: {np.mean(loss_per_fold)}")

"""### Three conv blocks. As a result of previous experiments, the activation function selected was leaky relu, Adam optimizer set at a learning rate of 0.0001, and with a loss function of categorical cross-entropy. Filter 1 size was 32, and Filter 2 was kept at 128, both with filter sizes of (3,3). For the dropout layers, the previously identified values were included in the search range in this next randomsearch"""

#Initial model:
def build_model(hp):
    model = Sequential()

    # Input layer
    model.add(Input(shape=(128, 128, 1)))

    # First Conv Block
    model.add(Conv2D(hp.Choice('filters_1', [32]), (3,3), activation='leaky_relu', padding='same'))
    model.add(BatchNormalization())
    model.add(MaxPooling2D((2,2)))

    # Second Conv Block
    model.add(Conv2D(hp.Choice('filters_2', [128]), (3,3), activation='leaky_relu', padding='same'))
    model.add(BatchNormalization())
    model.add(Conv2D(hp.Choice('filters_2', [128]), (3,3), activation='leaky_relu', padding='same'))
    model.add(BatchNormalization())
    model.add(MaxPooling2D((2,2)))

    # Third Conv Block
    model.add(Conv2D(hp.Choice('filters_3', [128, 256, 512]), (3,3), activation='leaky_relu', padding='same'))
    model.add(BatchNormalization())
    model.add(Conv2D(hp.Choice('filters_3', [128, 256, 512]), (3,3), activation='leaky_relu', padding='same'))
    model.add(BatchNormalization())
    model.add(MaxPooling2D((2,2)))

    # Flatten layer
    model.add(Flatten())

    # Fully Connected Layers
    model.add(Dense(hp.Int('dense_units_1', 384, 512, step=128), activation='leaky_relu'))
    model.add(Dropout(hp.Choice('dropout_1', [0.3])))
    model.add(Dense(hp.Int('dense_units_2', 128, 256, step=64), activation='leaky_relu'))
    model.add(Dropout(hp.Choice('dropout_2', [0.3])))

    # Output Layer
    model.add(Dense(4, activation='softmax'))  # 4 classes

    # Compile Model
    model.compile(
        optimizer=Adam(learning_rate=hp.Choice('learning_rate', [1e-4])),
        loss='categorical_crossentropy',
        metrics=metrics
    )

    return model

# Keras Tuner - Random Search
tuner = kt.RandomSearch(
    build_model,
    objective='val_accuracy',
    max_trials=4,  # Number of different models to test
    executions_per_trial=1,  # Number of times each model is trained
    directory='tuner_results',
    project_name='cnn_tuning'
)

# Clear session to avoid memory issues
K.clear_session()

# Run the search
tuner.search(X_train_final, y_train_final, epochs=8, validation_data=(X_val, y_val), verbose=1)

best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]
print(best_hps.values)

best_model = tuner.hypermodel.build(best_hps)
best_model.fit(X_train_final, y_train_final, epochs=8,
               validation_data=(X_val, y_val),
               batch_size= 32,  # Adjust batch size based on available memory
               verbose=1,  # Shows progress during training,
               callbacks=[early_stopping, model_checkpoint])

test_acc = best_model.evaluate(X_test, y_test_one_hot, verbose=1)
print(f"Test Accuracy: {test_acc}")

"""### Stratified 5 Kfold CV:"""

# Clear session to avoid memory issues
K.clear_session()

# Shuffle data to ensure randomness
X, y_cat = shuffle(X, y_cat, random_state=42)

# Stratified K-Fold setup
n_splits = 5
skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)

# Function to create CNN model
def create_cnn():
    input_shape=(128,128,1)
    model = keras.Sequential([
        #Block 1
        keras.layers.Input(shape=input_shape),  # Explicit input layer
        keras.layers.Conv2D(32, (3, 3), activation='leaky_relu', padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.MaxPooling2D((2, 2)),
        #Block 2
        keras.layers.Conv2D(128, (3, 3), activation='leaky_relu', padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.Conv2D(128, (3, 3), activation='leaky_relu', padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.MaxPooling2D((2, 2)),
        #Block 3
        keras.layers.Conv2D(128, (3, 3), activation='leaky_relu', padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.Conv2D(128, (3, 3), activation='leaky_relu', padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.MaxPooling2D((2, 2)),
        #Final Pieces
        keras.layers.Flatten(),
        keras.layers.Dense(512, activation='leaky_relu'),
        keras.layers.Dropout(0.3),
        keras.layers.Dense(128, activation='leaky_relu'),
        keras.layers.Dropout(0.3),
        keras.layers.Dense(num_classes, activation='softmax')
    ])

    model.compile(optimizer=Adam(learning_rate=0.0001),
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    return model

# Store accuracies
accuracies = []
losses = []

# K-Fold Cross-Validation loop
for fold, (train_index, test_index) in enumerate(skf.split(X, y)):
    print(f"Fold {fold+1}/{n_splits}")

    # Split dataset
    X_train_cv, X_test_cv = X[train_index], X[test_index]
    y_train_cv, y_test_cv = y_cat[train_index], y_cat[test_index]

    # Compute Class Weights (use original y labels, not one-hot encoded)
    class_weights = compute_class_weight(class_weight="balanced", classes=np.unique(y), y=y[train_index])
    class_weight_dict = dict(enumerate(class_weights))

    # Create a new CNN model instance for each fold
    model = create_cnn()

    # Train the model
    model.fit(X_train_cv, y_train_cv, epochs=8, batch_size=32,
              verbose=1, class_weight=class_weight_dict)  # Include class weights

    # Evaluate the model
    loss, accuracy = model.evaluate(X_test_cv, y_test_cv, verbose=0)
    accuracies.append(accuracy)
    losses.append(loss)
    print(f"Fold {fold+1} Loss: {loss}, Accuracy: {accuracy}\n")

# Print final cross-validation results
final_loss = np.mean(losses)
final_accuracy = np.mean(accuracies)

print(f"Final Average Loss across {n_splits} folds: {final_loss}")
print(f"Final Average Accuracy across {n_splits} folds: {final_accuracy}")

"""### 5 K-fold CV:"""

# Clear session to avoid memory issues
K.clear_session()


# Initialize 10-fold cross-validation
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# Store accuracy results
accuracy_per_fold = []
loss_per_fold = []

# Callbacks
checkpoint = ModelCheckpoint(
        '10kfold_mri_model.keras',
        monitor='val_accuracy',
        save_best_only=True,
        mode='max',
        verbose=1
    )

early_stopping = EarlyStopping(
    monitor='val_loss',  # Monitor validation loss
    patience=4,  # Stop training if val_loss does not improve for 5 consecutive epochs
    restore_best_weights=True  # Restore the best model weights after stopping
    )

def create_cnn():
    input_shape=(128,128,1)
    model = keras.Sequential([
        #Block 1
        keras.layers.Input(shape=input_shape),  # Explicit input layer
        keras.layers.Conv2D(32, (3, 3), activation='leaky_relu', padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.MaxPooling2D((2, 2)),
        #Block 2
        keras.layers.Conv2D(128, (3, 3), activation='leaky_relu', padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.Conv2D(128, (3, 3), activation='leaky_relu', padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.MaxPooling2D((2, 2)),
        #Block 3
        keras.layers.Conv2D(128, (3, 3), activation='leaky_relu', padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.Conv2D(128, (3, 3), activation='leaky_relu', padding='same'),
        keras.layers.BatchNormalization(),
        keras.layers.MaxPooling2D((2, 2)),
        #Final Pieces
        keras.layers.Flatten(),
        keras.layers.Dense(512, activation='leaky_relu'),
        keras.layers.Dropout(0.3),
        keras.layers.Dense(128, activation='leaky_relu'),
        keras.layers.Dropout(0.3),
        keras.layers.Dense(num_classes, activation='softmax')
    ])

    model.compile(optimizer=Adam(learning_rate=0.0001),
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    return model

# Perform cross-validation
for fold_no, (train_idx, val_idx) in enumerate(kf.split(X), start=1):
    print(f"\nTraining on Fold {fold_no}/5...")

    # Split data into training and validation sets
    x_train_fold, x_val_fold = X[train_idx], X[val_idx]
    y_train_fold, y_val_fold = y_cat[train_idx], y_cat[val_idx]

    # Create a new model instance for each fold
    model = create_cnn()

    # Train the model
    model.fit(
        x_train_fold, y_train_fold,
        epochs=8, batch_size=64,
        validation_data=(x_val_fold, y_val_fold),
        verbose=1,
        callbacks=[checkpoint, early_stopping]
    )
    # Load the best model before evaluation
    best_model = load_model('10kfold_mri_model.keras')

    # Evaluate the model
    loss, accuracy = best_model.evaluate(x_val_fold, y_val_fold, verbose=0)
    print(f"Fold {fold_no} - Loss: {loss}, Accuracy: {accuracy}")

    # Store results
    loss_per_fold.append(loss)
    accuracy_per_fold.append(accuracy)

# Print final cross-validation results
print("\nCross-Validation Results:")
print(f"Final Average Accuracy: {np.mean(accuracy_per_fold)}")
print(f"Final Average Loss: {np.mean(loss_per_fold)}")

"""<br /><br/>
# <b><center><font color="navy">Experiment 1b: <br /> Impact of Data Augmentation on MRI Image Classification Using the Best CNN from Experiment 1a
<br /><br />
"""

datagen = ImageDataGenerator(
    #preprocessing_function=adjust_brightness_and_contrast,  # Apply custom brightness and contrast adjustment
    width_shift_range=0.3,  # Shift width by 20%
    height_shift_range=0.3, # Shift height by 20%
    zoom_range=0.1,         # Zoom in/out
    fill_mode='nearest'     # Filling strategy for empty pixels
)

#X_train, X_test, y_train_one_hot, y_test_one_hot

# Augment images
augmented_images = []
for img_array in train_data['img_arr'].values:
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension (1, 128, 128, 1)
    img_array = np.expand_dims(img_array, axis=-1)
    augmented_img = next(datagen.flow(img_array, batch_size=1))[0]  # Apply augmentation
    augmented_images.append(augmented_img)

# Stack images into a 4D NumPy array
X_train_augmented = np.stack(augmented_images)  # Convert list of arrays into a single 4D NumPy array

# Ensure the shape is (num_samples, 128, 128, 1) for grayscale images
#if X_train_augmented.ndim == 3:
#    X_train_augmented = np.expand_dims(X_train_augmented, axis=-1)

# Normalize images to range [0,1] if necessary
X_train_augmented = X_train_augmented.astype('float32') / 255.0

# Define how many images to display
num_images = 10  # Display first 10 images

# Create a figure with subplots (5 rows, 2 columns)
fig, ax = plt.subplots(5, 2, figsize=(10, 8))

# Flatten the axes array for easy iteration
axs = ax.flatten()

# Loop through the first few augmented images and display them
for i in range(num_images):
    axs[i].imshow(X_train_augmented[i].squeeze(), cmap="gray")  # Squeeze to remove singleton dimens

# Split training data into training and validation sets (80% train, 30% val)
X_train_aug, X_val_aug, y_train_aug, y_val_aug = train_test_split(X_train_augmented, y_train_one_hot, test_size=0.3, random_state=42, stratify=y_train_encoded)

K.clear_session()

# Compile model
model.compile(optimizer=optimizer,
              loss='categorical_crossentropy',
              metrics=metrics)

# Model Summary
model.summary()

history = cnn_aug = model.fit(
                X_train_aug, y_train_aug,  # Training data
                validation_data=(X_val_aug, y_val_aug),  # Validation data
                epochs=10,  # Number of training cycles
                batch_size=32,  # Adjust batch size based on available memory
                verbose=1,  # Shows progress during training
                callbacks=[early_stopping, model_checkpoint] )

# Extract training history
epochs = range(1, len(cnn_aug.history['accuracy']) + 1)

# Plot Accuracy
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(epochs, cnn_aug.history['accuracy'], label='Training Accuracy')
plt.plot(epochs, cnn_aug.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training vs Validation Accuracy')

# Plot Loss
plt.subplot(1, 2, 2)
plt.plot(epochs, cnn_aug.history['loss'], label='Training Loss')
plt.plot(epochs, cnn_aug.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Training vs Validation Loss')

plt.show()

test_acc = model.evaluate(X_test, y_test_one_hot, verbose=1)
print(f"Test Accuracy: {test_acc}")

"""<br /><br/>
# <b><center><font color="navy">Experiment 2a: <br />Transfer Learning for Alzheimer's Stage Classification: Leveraging CNNs with MRI Imaging
<br /><br />

### InceptionV3 Prep: Convert to RGB
"""

# Convert grayscale to 3 channels by duplicating the single channel
#X_train_rgb = np.repeat(X_train, 3, axis=-1)
#X_test_rgb = np.repeat(X_test, 3, axis=-1)

# Preprocess for InceptionV3
#X_train_rgb = preprocess_input(X_train_rgb)
#X_test_rgb = preprocess_input(X_test_rgb)

# Convert list of image arrays into a single NumPy array
X_train_rgb = np.stack(train_data['img_arr'].values).astype('float32')
X_test_rgb = np.stack(test_data['img_arr'].values).astype('float32')

# Ensure the shape is (num_samples, 128, 128, 3) for RGB images
if X_train_rgb.ndim == 3:
    X_train_rgb = np.expand_dims(X_train_rgb, axis=-1)  # Add channel dimension if missing
if X_test_rgb.ndim == 3:
    X_test_rgb = np.expand_dims(X_test_rgb, axis=-1)

# Handle grayscale images by converting to 3 channels if necessary
if X_train_rgb.shape[-1] == 1:
    X_train_rgb = np.repeat(X_train_rgb, 3, axis=-1)
if X_test_rgb.shape[-1] == 1:
    X_test_rgb = np.repeat(X_test_rgb, 3, axis=-1)

# Compute mean and standard deviation (channel-wise across all images)
mean = np.mean(X_train_rgb, axis=(0, 1, 2), keepdims=True)  # Compute mean per channel
std = np.std(X_train_rgb, axis=(0, 1, 2), keepdims=True)    # Compute std per channel

mean_test = np.mean(X_test_rgb, axis=(0, 1, 2), keepdims=True)  # Compute mean per channel
std_test = np.std(X_test_rgb, axis=(0, 1, 2), keepdims=True)    # Compute std per channel


# Apply standardization
X_train_rgb = (X_train_rgb - mean) / std
X_test_rgb = (X_test_rgb - mean_test) / std_test  # Use training set mean & std for test data

X_train_rgb.shape, X_test_rgb.shape

# Convert list of image arrays into a single 4D NumPy array
#X_train_rgb = np.stack(train_data['img_arr'].values).astype('float32') / 255.0  # Normalize while stacking
#X_test_rgb = np.stack(test_data['img_arr'].values).astype('float32') / 255.0    # Normalize while stacking

# Ensure the shape is (num_samples, 128, 128, 3) for RGB images
#if X_train_rgb.ndim == 3:
#    X_train_rgb = np.expand_dims(X_train_rgb, axis=-1)  # Add channel dimension if missing
#if X_test_rgb.ndim == 3:
#    X_test_rgb = np.expand_dims(X_test_rgb, axis=-1)

# Handle grayscale images by converting to 3 channels if necessary
#if X_train_rgb.shape[-1] == 1:
#    X_train_rgb = np.repeat(X_train_rgb, 3, axis=-1)
#if X_test_rgb.shape[-1] == 1:
#    X_test_rgb = np.repeat(X_test_rgb, 3, axis=-1)

#X_train_rgb.shape
#X_test_rgb.shape

# Create a custom model based on InceptionV3
def build_inception_model():
    # Set up input tensor for 128x128 images with 3 channels
    #input_tensor = Input(shape=(128, 128, 3))

    # Load InceptionV3 without the top layer and with pre-trained weights
    base_model = InceptionV3(
        weights='imagenet',
        include_top=False,
        input_shape=(128, 128, 3)
    )

    # Freeze the base model layers
    base_model.trainable = False

    # Add custom layers for classification
    x = base_model.output
    #x = MaxPooling2D((2, 2))(x)
    x = GlobalAveragePooling2D()(x)  # Efficient pooling instead of Flatten
    #x = Flatten()(x)
    x = Dense(512, kernel_initializer='he_normal')(x)
    x = BatchNormalization()(x)  # Normalize activations
    x = tf.keras.layers.Activation('swish')(x)
    x = Dropout(0.4)(x)
    x = Dense(256, kernel_initializer='he_normal')(x)
    x = BatchNormalization()(x)  # Normalize activations
    x = tf.keras.layers.Activation('swish')(x)
    x = Dropout(0.4)(x)
    predictions = Dense(4, activation='softmax')(x)

    # Create the final model
    model = Model(inputs=base_model.input, outputs=predictions)

    # Compile the model
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    return model

# Split training data into training and validation sets (70% train, 30% val)
X_train_inc, X_val_inc, y_train_inc, y_val_inc = train_test_split(X_train_rgb, y_train_one_hot, test_size=0.3, random_state=42, stratify=y_train_encoded)

"""##### Leaky ReLu"""

K.clear_session()

# Build model
model = build_inception_model()
print("Model created successfully")

# Callbacks
checkpoint = ModelCheckpoint(
        'inception_mri_model.keras',
        monitor='val_accuracy',
        save_best_only=True,
        mode='max',
        verbose=1
    )

early_stopping = EarlyStopping(
    monitor='val_loss',  # Monitor validation loss
    patience=5,  # Stop training if val_loss does not improve for 5 consecutive epochs
    restore_best_weights=True  # Restore the best model weights after stopping
    )

# Train the model
history = model.fit(
        X_train_inc,
        y_train_inc,
        batch_size=32,
        epochs=25,
        validation_data=(X_val_inc, y_val_inc),
        callbacks=[checkpoint, early_stopping]
    )

# Load the best model before evaluation
best_model = load_model('inception_mri_model.keras')

# Evaluate the model
test_loss, test_acc = best_model.evaluate(X_test_rgb, y_test_one_hot)
print(f"Test accuracy: {test_acc}; Test loss: {test_loss}")

plt.figure(figsize=(12, 5))

# Plot accuracy
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Accuracy and Loss')
plt.xlabel('Epoch')
plt.ylabel('Accuracy and Loss')
plt.legend()

plt.tight_layout()
plt.show()

# Get predictions
y_pred = best_model.predict(X_test_rgb)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test_one_hot, axis=1)

# Create confusion matrix
cm = confusion_matrix(y_true, y_pred_classes)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

# Print classification report
class_names = [f'Class {i}' for i in range(num_classes)]
print(classification_report(y_true, y_pred_classes, target_names=class_names))

"""##### Swish lr = 0.00001"""

K.clear_session()

# Build model
model = build_inception_model()
print("Model created successfully")

# Callbacks
checkpoint = ModelCheckpoint(
        'inception_mri_model.keras',
        monitor='val_accuracy',
        save_best_only=True,
        mode='max',
        verbose=1
    )

early_stopping = EarlyStopping(
    monitor='val_loss',  # Monitor validation loss
    patience=5,  # Stop training if val_loss does not improve for 5 consecutive epochs
    restore_best_weights=True  # Restore the best model weights after stopping
    )

# Train the model
history = model.fit(
        X_train_inc,
        y_train_inc,
        batch_size=32,
        epochs=25,
        validation_data=(X_val_inc, y_val_inc),
        callbacks=[checkpoint, early_stopping]
    )

# Load the best model before evaluation
best_model = load_model('inception_mri_model.keras')

# Evaluate the model
test_loss, test_acc = best_model.evaluate(X_test_rgb, y_test_one_hot)
print(f"Test accuracy: {test_acc}; Test loss: {test_loss}")

plt.figure(figsize=(12, 5))

# Plot accuracy
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Accuracy and Loss')
plt.xlabel('Epoch')
plt.ylabel('Accuracy and Loss')
plt.legend()

plt.tight_layout()
plt.show()

# Get predictions
y_pred = best_model.predict(X_test_rgb)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test_one_hot, axis=1)

# Create confusion matrix
cm = confusion_matrix(y_true, y_pred_classes)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

# Print classification report
class_names = [f'Class {i}' for i in range(num_classes)]
print(classification_report(y_true, y_pred_classes, target_names=class_names))

"""### VGG16"""

def build_vgg16_model():
    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))

    # Freeze the base model layers
    base_model.trainable = False

        # Add custom layers for classification
    x = base_model.output
    x = MaxPooling2D((2, 2))(x)
    x = Flatten()(x)
    x = Dense(384)(x)
    x = BatchNormalization()(x)  # Normalize activations
    x = tf.keras.layers.Activation('swish')(x)
    x = Dropout(0.4)(x)
    x = Dense(256)(x)
    x = BatchNormalization()(x)  # Normalize activations
    x = tf.keras.layers.Activation('swish')(x)
    x = Dropout(0.4)(x)
    predictions = Dense(4, activation='softmax')(x)

    # Create the final model
    model = Model(inputs=base_model.input, outputs=predictions)

        # Compile the model
    model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )

    return model

K.clear_session()

# Build model
model = build_vgg16_model()
print("Model created successfully")

# Callbacks
checkpoint = ModelCheckpoint(
        'vgg16_mri_model.keras',
        monitor='val_accuracy',
        save_best_only=True,
        mode='max',
        verbose=1
    )

early_stopping = EarlyStopping(
    monitor='val_loss',  # Monitor validation loss
    patience=5,  # Stop training if val_loss does not improve for 5 consecutive epochs
    restore_best_weights=True  # Restore the best model weights after stopping
    )

# Train the model
history = model.fit(
        X_train_inc,
        y_train_inc,
        batch_size=32,
        epochs=25,
        validation_data=(X_val_inc, y_val_inc),
        callbacks=[checkpoint, early_stopping]
    )

# Load the best model before evaluation
best_model = load_model('vgg16_mri_model.keras')

# Evaluate the model
test_loss, test_acc = best_model.evaluate(X_test_rgb, y_test_one_hot)
print(f"Test accuracy: {test_acc}; Test loss: {test_loss}")

plt.figure(figsize=(12, 5))

# Plot accuracy
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Accuracy and Loss')
plt.xlabel('Epoch')
plt.ylabel('Accuracy and Loss')
plt.legend()

plt.tight_layout()
plt.show()

# Get predictions
y_pred = best_model.predict(X_test_rgb)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test_one_hot, axis=1)

# Create confusion matrix
cm = confusion_matrix(y_true, y_pred_classes)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

# Print classification report
class_names = [f'Class {i}' for i in range(num_classes)]
print(classification_report(y_true, y_pred_classes, target_names=class_names))

"""### EfficientNet B1:"""

from tensorflow.keras.applications import EfficientNetB1


# Create a custom model based on InceptionV3
def build_efficientnet_model():
    # Set up input tensor for 128x128 images with 3 channels
    #input_tensor = Input(shape=(128, 128, 3))

    # Load InceptionV3 without the top layer and with pre-trained weights
    base_model = EfficientNetB1(
        weights='imagenet',
        include_top=False,
        input_shape=(128, 128, 3)
    )

    # Freeze the base model layers
    base_model.trainable = False

    # Add custom layers for classification
    x = base_model.output
    #x = MaxPooling2D((2, 2))(x)
    x = GlobalAveragePooling2D()(x)  # Efficient pooling instead of Flatten
    #x = Flatten()(x)
    x = Dense(512, kernel_initializer='he_normal')(x)
    x = BatchNormalization()(x)  # Normalize activations
    x = tf.keras.layers.Activation('swish')(x)
    x = Dropout(0.4)(x)
    x = Dense(256, kernel_initializer='he_normal')(x)
    x = BatchNormalization()(x)  # Normalize activations
    x = tf.keras.layers.Activation('swish')(x)
    x = Dropout(0.4)(x)
    predictions = Dense(4, activation='softmax')(x)

    # Create the final model
    model = Model(inputs=base_model.input, outputs=predictions)

    # Compile the model
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    return model

K.clear_session()

# Build model
model = build_efficientnet_model()
print("Model created successfully")

# Callbacks
checkpoint = ModelCheckpoint(
        'effnet_model.keras',
        monitor='val_accuracy',
        save_best_only=True,
        mode='max',
        verbose=1
    )

early_stopping = EarlyStopping(
    monitor='val_loss',  # Monitor validation loss
    patience=5,  # Stop training if val_loss does not improve for 5 consecutive epochs
    restore_best_weights=True  # Restore the best model weights after stopping
    )

# Train the model
history = model.fit(
        X_train_inc,
        y_train_inc,
        batch_size=32,
        epochs=25,
        validation_data=(X_val_inc, y_val_inc),
        callbacks=[checkpoint, early_stopping]
    )

# Load the best model before evaluation
best_model = load_model('effnet_model.keras')

# Evaluate the model
test_loss, test_acc = best_model.evaluate(X_test_rgb, y_test_one_hot)
print(f"Test accuracy: {test_acc}; Test loss: {test_loss}")

plt.figure(figsize=(12, 5))

# Plot accuracy
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Accuracy and Loss')
plt.xlabel('Epoch')
plt.ylabel('Accuracy and Loss')
plt.legend()

plt.tight_layout()
plt.show()

# Get predictions
y_pred = best_model.predict(X_test_rgb)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test_one_hot, axis=1)

# Create confusion matrix
cm = confusion_matrix(y_true, y_pred_classes)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

# Print classification report
class_names = [f'Class {i}' for i in range(num_classes)]
print(classification_report(y_true, y_pred_classes, target_names=class_names))

"""<br /><br/>
# <b><center><font color="navy">Experiment 2b: <br />Impact of Data Augmentation on Alzheimer's Stage Classification Using Transfer Learning
<br /><br />

#### InceptionV3
"""

datagen = ImageDataGenerator(
    #preprocessing_function=adjust_brightness_and_contrast,  # Apply custom brightness and contrast adjustment
    width_shift_range=0.1,  # Shift width by 20%
    height_shift_range=0.1, # Shift height by 20%
    zoom_range=0.1,         # Zoom in/out
    fill_mode='nearest'     # Filling strategy for empty pixels
)

# Augment images
augmented_images = []
for img_array in train_data['img_arr'].values:
    img_array = np.expand_dims(img_array, axis=-1)  # Ensure shape is (128, 128, 1)

    # Convert grayscale (1 channel) to RGB (3 channels)
    img_array_rgb = np.concatenate([img_array] * 3, axis=-1)  # Shape: (128, 128, 3)

    img_array_rgb = np.expand_dims(img_array_rgb, axis=0)  # Add batch dimension (1, 128, 128, 3)
    augmented_img = next(datagen.flow(img_array_rgb, batch_size=1))[0]  # Apply augmentation
    augmented_images.append(augmented_img)

# Stack images into a 4D NumPy array (num_samples, 128, 128, 3)
X_train_augmented = np.stack(augmented_images)

# Normalize images to range [0,1]
X_train_augmented = X_train_augmented.astype('float32') / 255.0

# Create a custom model based on InceptionV3
def build_inception_model():
    # Set up input tensor for 128x128 images with 3 channels
    #input_tensor = Input(shape=(128, 128, 3))

    # Load InceptionV3 without the top layer and with pre-trained weights
    base_model = InceptionV3(
        weights='imagenet',
        include_top=False,
        input_shape=(128, 128, 3)
    )

    # Freeze the base model layers
    base_model.trainable = False

    # Add custom layers for classification
    x = base_model.output
    x = MaxPooling2D((2, 2))(x)
    x = Flatten()(x)
    x = Dense(384)(x)
    x = BatchNormalization()(x)  # Normalize activations
    x = tf.keras.layers.Activation('swish')(x)
    x = Dropout(0.4)(x)
    x = Dense(256)(x)
    x = BatchNormalization()(x)  # Normalize activations
    x = tf.keras.layers.Activation('swish')(x)
    x = Dropout(0.4)(x)
    predictions = Dense(4, activation='softmax')(x)

    # Create the final model
    model = Model(inputs=base_model.input, outputs=predictions)

    # Compile the model
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    return model

# Split training data into training and validation sets (70% train, 30% val)
X_train_inc, X_val_inc, y_train_inc, y_val_inc = train_test_split(X_train_augmented, y_train_one_hot, test_size=0.3, random_state=42, stratify=y_train_encoded)

K.clear_session()

# Build model
model = build_inception_model()
print("Model created successfully")

# Callbacks
checkpoint = ModelCheckpoint(
        'inception_aug_mri_model.keras',
        monitor='val_accuracy',
        save_best_only=True,
        mode='max',
        verbose=1
    )

early_stopping = EarlyStopping(
    monitor='val_loss',  # Monitor validation loss
    patience=5,  # Stop training if val_loss does not improve for 5 consecutive epochs
    restore_best_weights=True  # Restore the best model weights after stopping
    )

# Train the model
history = model.fit(
        X_train_inc,
        y_train_inc,
        batch_size=32,
        epochs=25,
        validation_data=(X_val_inc, y_val_inc),
        callbacks=[checkpoint, early_stopping]
    )

# Load the best model before evaluation
best_model = load_model('inception_aug_mri_model.keras')

# Evaluate the model
test_loss, test_acc = best_model.evaluate(X_test_rgb, y_test_one_hot)
print(f"Test accuracy: {test_acc}; Test loss: {test_loss}")

plt.figure(figsize=(12, 5))

# Plot accuracy
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Accuracy and Loss')
plt.xlabel('Epoch')
plt.ylabel('Accuracy and Loss')
plt.legend()

plt.tight_layout()
plt.show()

# Get predictions
y_pred = best_model.predict(X_test_rgb)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test_one_hot, axis=1)

# Create confusion matrix
cm = confusion_matrix(y_true, y_pred_classes)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

# Print classification report
class_names = [f'Class {i}' for i in range(num_classes)]
print(classification_report(y_true, y_pred_classes, target_names=class_names))

"""### VGG16"""

K.clear_session()

# Build model
model = build_vgg16_model()
print("Model created successfully")

# Callbacks
checkpoint = ModelCheckpoint(
        'vgg16_mri_model.keras',
        monitor='val_accuracy',
        save_best_only=True,
        mode='max',
        verbose=1
    )

early_stopping = EarlyStopping(
    monitor='val_loss',  # Monitor validation loss
    patience=5,  # Stop training if val_loss does not improve for 5 consecutive epochs
    restore_best_weights=True  # Restore the best model weights after stopping
    )

# Train the model
history = model.fit(
        X_train_inc,
        y_train_inc,
        batch_size=32,
        epochs=25,
        validation_data=(X_val_inc, y_val_inc),
        callbacks=[checkpoint, early_stopping]
    )

# Load the best model before evaluation
best_model = load_model('vgg16_mri_model.keras')

# Evaluate the model
test_loss, test_acc = best_model.evaluate(X_test_rgb, y_test_one_hot)
print(f"Test accuracy: {test_acc}; Test loss: {test_loss}")

plt.figure(figsize=(12, 5))

# Plot accuracy
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Accuracy and Loss')
plt.xlabel('Epoch')
plt.ylabel('Accuracy and Loss')
plt.legend()

plt.tight_layout()
plt.show()

# Get predictions
y_pred = best_model.predict(X_test_rgb)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test_one_hot, axis=1)

# Create confusion matrix
cm = confusion_matrix(y_true, y_pred_classes)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

# Print classification report
class_names = [f'Class {i}' for i in range(num_classes)]
print(classification_report(y_true, y_pred_classes, target_names=class_names))

"""### EffecientNet B1"""

K.clear_session()

# Build model
model = build_efficientnet_model()
print("Model created successfully")

# Callbacks
checkpoint = ModelCheckpoint(
        'vgg16_mri_model.keras',
        monitor='val_accuracy',
        save_best_only=True,
        mode='max',
        verbose=1
    )

early_stopping = EarlyStopping(
    monitor='val_loss',  # Monitor validation loss
    patience=5,  # Stop training if val_loss does not improve for 5 consecutive epochs
    restore_best_weights=True  # Restore the best model weights after stopping
    )

# Train the model
history = model.fit(
        X_train_inc,
        y_train_inc,
        batch_size=32,
        epochs=25,
        validation_data=(X_val_inc, y_val_inc),
        callbacks=[checkpoint, early_stopping]
    )

# Load the best model before evaluation
best_model = load_model('vgg16_mri_model.keras')

# Evaluate the model
test_loss, test_acc = best_model.evaluate(X_test_rgb, y_test_one_hot)
print(f"Test accuracy: {test_acc}; Test loss: {test_loss}")

plt.figure(figsize=(12, 5))

# Plot accuracy
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Accuracy and Loss')
plt.xlabel('Epoch')
plt.ylabel('Accuracy and Loss')
plt.legend()

plt.tight_layout()
plt.show()

# Get predictions
y_pred = best_model.predict(X_test_rgb)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test_one_hot, axis=1)

# Create confusion matrix
cm = confusion_matrix(y_true, y_pred_classes)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

# Print classification report
class_names = [f'Class {i}' for i in range(num_classes)]
print(classification_report(y_true, y_pred_classes, target_names=class_names))